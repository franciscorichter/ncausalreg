<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Getting Started · NCR</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../css/styles.css">
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
</head>

<body>
    <header>
        <div class="container header-container">
            <div class="logo"><a href="../index.html">Neural<span>Causal</span>Reg</a></div>
            <nav><button class="mobile-menu-btn"><i class="fas fa-bars"></i></button>
                <ul>
                    <li><a href="../index.html">Home</a></li>
                    <li><a class="active" href="index.html">Docs</a></li>
                    <li><a href="../examples/index.html">Examples</a></li>
                    <li><a href="https://github.com/your‑org/ncr" target="_blank">GitHub</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <div class="container docs-container">
        <aside class="docs-sidebar">
            <h3>Documentation</h3>
            <ul>
                <li><a href="index.html">Introduction</a></li>
                <li><a href="installation.html">Installation</a></li>
                <li><a class="active" href="getting-started.html">Getting Started</a></li>
                <li><a href="theory.html">Theory</a></li>
                <li><a href="api.html">API Reference</a></li>
            </ul>
        </aside>

        <main class="docs-content">
            <h1>Quick start</h1>

            <h2>Train NCR on Colored‑MNIST</h2>
            <pre><code class="python">import torch, torchvision
from torch.utils.data import DataLoader
from ncr import NCRNet, train_ncr, risk_gap, accuracy

# 1. two synthetic environments
def colour_fn(env):
    red, green = (1,0,0), (0,1,0)
    def f(img):
        rgb = red if (img.sum()&1) ^ env else green
        return torch.tensor(rgb)[:,None,None] * torchvision.transforms.ToTensor()(img)
    return f

root = "./data"
base = torchvision.datasets.MNIST(root, train=True, download=True)
env0 = [(colour_fn(0)(img), torch.tensor([y&lt;5],dtype=torch.float32)) for img,y in base]
env1 = [(colour_fn(1)(img), torch.tensor([y&lt;5],dtype=torch.float32)) for img,y in base]
loaders = [DataLoader(env0, batch_size=64, shuffle=True),
           DataLoader(env1, batch_size=64, shuffle=True)]

# 2. model & loss
net = NCRNet(3*28*28, (256,256), 1)
crit = torch.nn.BCEWithLogitsLoss()

# 3. train with NCR (λ=1)
train_ncr(net, loaders, crit, epochs=5, lambda_reg=1.0)

# 4. evaluate
print("OOD acc:", accuracy(net, loaders[1]))
</code></pre>

            <p>This tiny script matches the workflow in our <code>experiments</code>
                folder. For a full benchmark, see the
                <a href="../examples/index.html">Examples</a>.
            </p>
        </main>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="../js/main.js"></script>
</body>

</html>